"""
Vulnerability Scorer Component
===============================
Orchestrates the vulnerability scoring pipeline for MCP repositories.

Coordinates SBOM generation, OSV scanning, and time-decay scoring to produce
FICO-style vulnerability scores (300-850 range) for the MCP Security Analysis System.

Author: MCP Security Team
"""

import asyncio
import json
import logging
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

# Import our tools
import sys
sys.path.append(str(Path(__file__).parent.parent.parent.parent))

from sbom_generator import SBOMGenerator, GeneratorType, SBOMFormat
from osv_scanner import OSVScanner
from vulnerability_time_scorer import VulnerabilityTimeScorer, VulnerabilityScore

logger = logging.getLogger(__name__)


@dataclass
class VulnerabilityAssessment:
    """Complete vulnerability assessment for a repository."""
    repository: str
    fico_score: int
    grade: str  # A, B, C, F
    sbom_path: str
    total_vulnerabilities: int
    critical_count: int
    high_count: int
    medium_count: int
    low_count: int
    kev_count: int
    oldest_critical_days: Optional[int]
    mean_vulnerability_age: float
    remediation_priorities: List[Dict]
    scan_timestamp: str
    processing_time: float

    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization."""
        return {
            'repository': self.repository,
            'fico_score': self.fico_score,
            'grade': self.grade,
            'sbom_path': self.sbom_path,
            'total_vulnerabilities': self.total_vulnerabilities,
            'critical_count': self.critical_count,
            'high_count': self.high_count,
            'medium_count': self.medium_count,
            'low_count': self.low_count,
            'kev_count': self.kev_count,
            'oldest_critical_days': self.oldest_critical_days,
            'mean_vulnerability_age': self.mean_vulnerability_age,
            'remediation_priorities': self.remediation_priorities,
            'scan_timestamp': self.scan_timestamp,
            'processing_time': self.processing_time
        }


class VulnerabilityScorer:
    """
    Main orchestrator for vulnerability scoring pipeline.

    Coordinates:
    1. SBOM generation
    2. OSV vulnerability scanning
    3. Time-decay scoring
    4. Remediation prioritization
    """

    def __init__(self,
                 sbom_generator: Optional[SBOMGenerator] = None,
                 osv_scanner: Optional[OSVScanner] = None,
                 time_scorer: Optional[VulnerabilityTimeScorer] = None,
                 cache_dir: Optional[Path] = None):
        """
        Initialize vulnerability scorer.

        Args:
            sbom_generator: SBOM generator instance (or create default)
            osv_scanner: OSV scanner instance (or create default)
            time_scorer: Time-decay scorer instance (or create default)
            cache_dir: Directory for caching results
        """
        # Initialize tools with defaults if not provided
        self.sbom_generator = sbom_generator or SBOMGenerator(
            generator_type=GeneratorType.CDXGEN,
            output_format=SBOMFormat.CYCLONEDX,
            include_dev_deps=False,  # Exclude dev deps for security scoring
            deep_scan=True
        )

        self.osv_scanner = osv_scanner or OSVScanner(
            offline_mode=False,
            check_kev=True,  # Always check KEV
            min_cvss=0.0  # Report all vulnerabilities
        )

        self.time_scorer = time_scorer or VulnerabilityTimeScorer(
            base_score=850,
            min_score=300
        )

        self.cache_dir = cache_dir or Path(".cache/vulnerability_scores")
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    async def score_repository(self, repo_path: str) -> VulnerabilityAssessment:
        """
        Complete vulnerability scoring pipeline for a repository.

        Args:
            repo_path: Path to repository

        Returns:
            VulnerabilityAssessment with complete scoring results
        """
        start_time = datetime.now()
        repo_path = Path(repo_path).resolve()
        repo_name = repo_path.name

        logger.info(f"Starting vulnerability assessment for {repo_name}")

        try:
            # Step 1: Generate SBOM
            logger.info("Generating SBOM...")
            sbom_result = await self.sbom_generator.generate_sbom(str(repo_path))

            if not sbom_result.success:
                logger.error(f"SBOM generation failed: {sbom_result.error_message}")
                return self._create_error_assessment(repo_name, "SBOM generation failed")

            logger.info(f"SBOM generated: {sbom_result.component_count} components")

            # Step 2: Scan for vulnerabilities
            logger.info("Scanning for vulnerabilities...")
            scan_result = await self.osv_scanner.scan_sbom(sbom_result.sbom_path)

            if not scan_result.success:
                logger.error(f"Vulnerability scan failed: {scan_result.error_message}")
                return self._create_error_assessment(repo_name, "Vulnerability scan failed")

            logger.info(f"Found {len(scan_result.vulnerabilities)} vulnerabilities")

            # Step 3: Apply time-decay scoring
            logger.info("Calculating time-decay score...")
            score = self.time_scorer.calculate_score(scan_result, repository=repo_name)

            # Step 4: Generate remediation priorities
            priorities = self.time_scorer.get_remediation_priority(score)

            # Calculate processing time
            processing_time = (datetime.now() - start_time).total_seconds()

            # Create assessment
            assessment = VulnerabilityAssessment(
                repository=repo_name,
                fico_score=score.fico_score,
                grade=self._score_to_grade(score.fico_score),
                sbom_path=sbom_result.sbom_path,
                total_vulnerabilities=score.total_vulnerabilities,
                critical_count=score.severity_counts.get('critical', 0),
                high_count=score.severity_counts.get('high', 0),
                medium_count=score.severity_counts.get('medium', 0),
                low_count=score.severity_counts.get('low', 0),
                kev_count=score.kev_count,
                oldest_critical_days=score.oldest_critical_days,
                mean_vulnerability_age=score.mean_vulnerability_age,
                remediation_priorities=priorities,
                scan_timestamp=datetime.now().isoformat(),
                processing_time=processing_time
            )

            # Cache results
            await self._cache_assessment(assessment)

            logger.info(f"Assessment complete: Score={score.fico_score} Grade={assessment.grade}")

            return assessment

        except Exception as e:
            logger.error(f"Vulnerability assessment failed: {e}")
            return self._create_error_assessment(repo_name, str(e))

    async def batch_score_repositories(self,
                                      repo_paths: List[str],
                                      max_concurrent: int = 3) -> List[VulnerabilityAssessment]:
        """
        Score multiple repositories concurrently.

        Args:
            repo_paths: List of repository paths
            max_concurrent: Maximum concurrent assessments

        Returns:
            List of vulnerability assessments
        """
        semaphore = asyncio.Semaphore(max_concurrent)

        async def score_with_limit(repo_path):
            async with semaphore:
                return await self.score_repository(repo_path)

        tasks = [score_with_limit(repo) for repo in repo_paths]
        results = await asyncio.gather(*tasks)

        return results

    def _score_to_grade(self, fico_score: int) -> str:
        """Convert FICO score to letter grade."""
        if fico_score >= 800:
            return "A"
        elif fico_score >= 670:
            return "B"
        elif fico_score >= 580:
            return "C"
        else:
            return "F"

    def _create_error_assessment(self, repo_name: str, error_message: str) -> VulnerabilityAssessment:
        """Create assessment for error cases."""
        return VulnerabilityAssessment(
            repository=repo_name,
            fico_score=670,  # Neutral B grade
            grade="B",
            sbom_path="",
            total_vulnerabilities=0,
            critical_count=0,
            high_count=0,
            medium_count=0,
            low_count=0,
            kev_count=0,
            oldest_critical_days=None,
            mean_vulnerability_age=0.0,
            remediation_priorities=[],
            scan_timestamp=datetime.now().isoformat(),
            processing_time=0.0
        )

    async def _cache_assessment(self, assessment: VulnerabilityAssessment):
        """Cache assessment results."""
        cache_file = self.cache_dir / f"{assessment.repository}_vulnerability.json"
        with open(cache_file, 'w') as f:
            json.dump(assessment.to_dict(), f, indent=2)

    async def generate_report(self, assessment: VulnerabilityAssessment) -> str:
        """
        Generate human-readable vulnerability report.

        Args:
            assessment: Vulnerability assessment

        Returns:
            Formatted report string
        """
        report = []
        report.append(f"# Vulnerability Assessment Report")
        report.append(f"Repository: {assessment.repository}")
        report.append(f"Date: {assessment.scan_timestamp}")
        report.append(f"")

        # Score summary
        report.append(f"## Security Score")
        report.append(f"**FICO Score:** {assessment.fico_score} (Grade: {assessment.grade})")
        report.append(f"")

        # Vulnerability summary
        report.append(f"## Vulnerability Summary")
        report.append(f"- **Total Vulnerabilities:** {assessment.total_vulnerabilities}")
        report.append(f"- **Critical:** {assessment.critical_count}")
        report.append(f"- **High:** {assessment.high_count}")
        report.append(f"- **Medium:** {assessment.medium_count}")
        report.append(f"- **Low:** {assessment.low_count}")
        report.append(f"")

        # Risk indicators
        report.append(f"## Risk Indicators")
        if assessment.kev_count > 0:
            report.append(f"⚠️ **{assessment.kev_count} Known Exploited Vulnerabilities (KEV)**")
        if assessment.oldest_critical_days:
            report.append(f"⚠️ **Oldest Critical:** {assessment.oldest_critical_days} days old")
        report.append(f"- **Mean Vulnerability Age:** {assessment.mean_vulnerability_age} days")
        report.append(f"")

        # Remediation priorities
        if assessment.remediation_priorities:
            report.append(f"## Remediation Priorities")
            for priority in assessment.remediation_priorities:
                report.append(f"{priority['priority']}. **{priority['category']}**")
                report.append(f"   - {priority['action']}")
                report.append(f"   - Urgency: {priority['urgency']}")
            report.append(f"")

        # Footer
        report.append(f"---")
        report.append(f"*Processing time: {assessment.processing_time:.2f} seconds*")

        return "\n".join(report)


async def main():
    """Example usage of vulnerability scorer."""
    import sys

    if len(sys.argv) < 2:
        print("Usage: python vulnerability_scorer.py <repository_path>")
        sys.exit(1)

    repo_path = sys.argv[1]

    # Initialize scorer
    scorer = VulnerabilityScorer()

    # Score repository
    print(f"Assessing vulnerability risk for {repo_path}...")
    assessment = await scorer.score_repository(repo_path)

    # Generate report
    report = await scorer.generate_report(assessment)
    print(report)

    # Save detailed results
    output_file = f"{assessment.repository}_vulnerability_assessment.json"
    with open(output_file, 'w') as f:
        json.dump(assessment.to_dict(), f, indent=2)
    print(f"\nDetailed results saved to: {output_file}")


if __name__ == "__main__":
    asyncio.run(main())